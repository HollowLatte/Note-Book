import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as a,c as t,e as n}from"./app-QXbWND43.js";const s={},l=n(`<p>通常我们说的ES分词，在ES中称为analyzer，ES有默认的分词器standard，但是对检索中文不友好</p><h2 id="索引分词" tabindex="-1"><a class="header-anchor" href="#索引分词"><span>索引分词</span></a></h2><p>索引分词是指在建立索引时对文本进行分词处理，并将分词结果保存到索引中。在索引文本时，Elasticsearch 会根据设置的分析器对文本进行分词、过滤、标准化等操作，以便后续的搜索和聚合操作。索引分词通常会对文本进行更加精细的分词处理，以提高搜索结果的准确性。</p><h3 id="添加-修改索引分词器" tabindex="-1"><a class="header-anchor" href="#添加-修改索引分词器"><span>添加/修改索引分词器</span></a></h3><p>已经创建的索引是不可以添加或修改分词器的，需要创建一个新的索引，在新的索引上添加分词器。</p><p>添加分词器就是在索引的字段中配置<code>analyzer</code>属性。</p><p>例如，想给name字段配置ik分词器就可以进行如下配置：</p><div class="language-json line-numbers-mode" data-ext="json" data-title="json"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;text&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;analyzer&quot;</span><span class="token operator">:</span> <span class="token string">&quot;ik_max_word&quot;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="搜索分词" tabindex="-1"><a class="header-anchor" href="#搜索分词"><span>搜索分词</span></a></h2><p>搜索分词是指在查询时对<strong>输入的关键词</strong>进行分词处理，并将分词结果与索引中的分词结果进行匹配，以找到匹配的文档。在搜索时，Elasticsearch 会根据设置的分析器对查询语句进行分词、过滤、标准化等操作，以便与索引中的分词结果进行匹配。搜索分词通常会对查询语句进行较为宽松的分词处理，以提高搜索结果的召回率。</p><h2 id="分词验证" tabindex="-1"><a class="header-anchor" href="#分词验证"><span>分词验证</span></a></h2><p>可以通过ES提供的Analyzer API来测试分词情况。</p><p>测试ES默认的分词效果：</p><div class="language-http line-numbers-mode" data-ext="http" data-title="http"><pre class="language-http"><code>POST /_analyze

{
    &quot;analyzer&quot;: &quot;standard&quot;,
    &quot;text&quot;: &quot;[asdklad_lxc_qwekqlwn,jsdaisjd,asdasd]&quot;
}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>测试ik的分词效果：</p><div class="language-http line-numbers-mode" data-ext="http" data-title="http"><pre class="language-http"><code>POST /_analyze

{
    &quot;analyzer&quot;: &quot;ik_smart&quot;,
    &quot;text&quot;: &quot;我是一个粉刷匠，粉刷本领强。&quot;
}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,16),o=[l];function i(r,c){return a(),t("div",null,o)}const u=e(s,[["render",i],["__file","analyzer.html.vue"]]),h=JSON.parse('{"path":"/notebook/elasticsearch/analyzer/analyzer.html","title":"分词","lang":"zh-CN","frontmatter":{"title":"分词","author":null,"category":"Elasticsearch","tag":"Elasticsearch","description":"通常我们说的ES分词，在ES中称为analyzer，ES有默认的分词器standard，但是对检索中文不友好 索引分词 索引分词是指在建立索引时对文本进行分词处理，并将分词结果保存到索引中。在索引文本时，Elasticsearch 会根据设置的分析器对文本进行分词、过滤、标准化等操作，以便后续的搜索和聚合操作。索引分词通常会对文本进行更加精细的分词处理...","head":[["meta",{"property":"og:url","content":"https://hollowlatte.github.io/Note-Book/notebook/elasticsearch/analyzer/analyzer.html"}],["meta",{"property":"og:site_name","content":"Note-Book"}],["meta",{"property":"og:title","content":"分词"}],["meta",{"property":"og:description","content":"通常我们说的ES分词，在ES中称为analyzer，ES有默认的分词器standard，但是对检索中文不友好 索引分词 索引分词是指在建立索引时对文本进行分词处理，并将分词结果保存到索引中。在索引文本时，Elasticsearch 会根据设置的分析器对文本进行分词、过滤、标准化等操作，以便后续的搜索和聚合操作。索引分词通常会对文本进行更加精细的分词处理..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-03-26T17:48:20.000Z"}],["meta",{"property":"article:author","content":"Hollow-Latte"}],["meta",{"property":"article:tag","content":"Elasticsearch"}],["meta",{"property":"article:modified_time","content":"2024-03-26T17:48:20.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"分词\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-03-26T17:48:20.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Hollow-Latte\\",\\"url\\":\\"https://hollowlatte.github.io/Note-Book\\"}]}"]]},"headers":[{"level":2,"title":"索引分词","slug":"索引分词","link":"#索引分词","children":[{"level":3,"title":"添加/修改索引分词器","slug":"添加-修改索引分词器","link":"#添加-修改索引分词器","children":[]}]},{"level":2,"title":"搜索分词","slug":"搜索分词","link":"#搜索分词","children":[]},{"level":2,"title":"分词验证","slug":"分词验证","link":"#分词验证","children":[]}],"git":{"createdTime":1711475300000,"updatedTime":1711475300000,"contributors":[{"name":"hollowlatte","email":"hollowlatte@outlook.com","commits":1}]},"readingTime":{"minutes":1.51,"words":454},"filePathRelative":"notebook/elasticsearch/analyzer/analyzer.md","localizedDate":"2024年3月26日","excerpt":"<p>通常我们说的ES分词，在ES中称为analyzer，ES有默认的分词器standard，但是对检索中文不友好</p>\\n<h2>索引分词</h2>\\n<p>索引分词是指在建立索引时对文本进行分词处理，并将分词结果保存到索引中。在索引文本时，Elasticsearch\\n会根据设置的分析器对文本进行分词、过滤、标准化等操作，以便后续的搜索和聚合操作。索引分词通常会对文本进行更加精细的分词处理，以提高搜索结果的准确性。</p>\\n<h3>添加/修改索引分词器</h3>\\n<p>已经创建的索引是不可以添加或修改分词器的，需要创建一个新的索引，在新的索引上添加分词器。</p>\\n<p>添加分词器就是在索引的字段中配置<code>analyzer</code>属性。</p>","autoDesc":true}');export{u as comp,h as data};
